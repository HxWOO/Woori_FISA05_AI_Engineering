# 🏦 은행 마케팅 데이터 분류기 만들기

이번에는 은행 마케팅 데이터를 사용해 고객이 정기 예금에 가입할지 예측하는 전체 과정을 진행했다. 데이터 전처리부터 여러 모델 비교, 하이퍼파라미터 튜닝, 그리고 AutoML 도구인 PyCaret까지 사용해본 종합적인 경험이었다.

## 🎯 목차
1.  [데이터 준비 및 탐색](#1-데이터-준비-및-탐색-📥)
2.  [데이터 전처리](#2-데이터-전처리-✨)
3.  [여러 분류 모델링 및 비교](#3-여러-분류-모델링-및-비교-⚙️)
4.  [하이퍼파라미터 튜닝으로 모델 최적화](#4-하이퍼파라미터-튜닝으로-모델-최적화-🛠️)
5.  [AutoML 도구(PyCaret) 활용기](#5-automl-도구pycaret-활용기-🤖)
6.  [최종 정리 및 회고](#6-최종-정리-및-회고-✍️)

---

## 1. 데이터 준비 및 탐색 📥

UCI 저장소에 있는 은행 마케팅 데이터를 사용했다. 고객의 나이, 직업, 대출 여부 등 다양한 정보를 바탕으로 예금 가입 여부(`y`)를 예측하는 것이 목표다.

```python
from ucimlrepo import fetch_ucirepo

# 데이터셋 로드
bank_marketing = fetch_ucirepo(id=222)
X = bank_marketing.data.features
y = bank_marketing.data.targets
df_bank = pd.concat([X, y], axis=1)

# 데이터 기본 정보 확인
df_bank.info()
```

### 주요 탐색 결과
-   **Target 분포**: `no`와 `yes`의 비율이 약 8:1로, 데이터 불균형이 꽤 심했다. 이는 모델 평가 시 `accuracy`만 믿으면 안 된다는 신호다.
-   **결측치**: `missingno` 라이브러리로 확인했을 때, 눈에 띄는 결측치는 없었다.
-   **사후 정보 제외**: `duration` (통화 시간) 피처는 결과에 큰 영향을 주지만, 예측 시점에서는 알 수 없는 정보이므로 과감히 제외했다. 이게 현실적인 모델링의 첫걸음이었다.

## 2. 데이터 전처리 ✨

모델이 잘 학습할 수 있도록 데이터를 정제하는 과정이 정말 중요했다.

### 가. 수치형 데이터 스케일링

피처마다 값의 범위가 다르기 때문에 스케일링은 필수였다. 여러 스케일러를 비교해봤다.

-   **StandardScaler**: 평균 0, 분산 1로. 이상치에 덜 민감하고 일반적이라 최종 선택!
-   **MinMaxScaler**: 0과 1 사이로. 신경망에서 유용하지만 이상치에 민감.
-   **RobustScaler**: 중앙값과 IQR 사용. 이상치가 많을 때 효과적.
-   **MaxAbsScaler**: 절대값 기준. 희소 데이터에 유리.

```python
from sklearn.preprocessing import StandardScaler

num_cols = ['age', 'balance', 'day_of_week', 'campaign', 'pdays','previous']
scaler =  StandardScaler()

# train 데이터 기준으로 fit하고, train/test 모두 transform
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])
```

### 나. 범주형 데이터 인코딩

문자열 데이터를 모델이 이해할 수 있는 숫자로 바꿔야 했다.

-   **OneHotEncoder**: 각 카테고리를 새로운 피처로 만든다. 모델이 카테고리 간의 서열 관계를 오해하지 않도록 하는 가장 확실한 방법이었다. `drop='first'` 옵션으로 **다중공선성 문제**도 피하고 피처 수도 줄일 수 있었다.

```python
from sklearn.preprocessing import OneHotEncoder

cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact','month','poutcome']

# drop='first'로 첫 번째 카테고리를 제거해 모델 복잡도 감소
encoder = OneHotEncoder(drop='first')
encoder.fit(df_bank_ready[cat_cols])
encoder_data = encoder.transform(df_bank_ready[cat_cols])
```
:bulb: **다중공선성 문제란?**
> 다중공선성은 회귀 분석에서 독립 변수들끼리 강하게 상관되어 계수 추정이 불안정해지고 해석이 어려워지는 문제입니다.
해결 방법으로는 변수 제거, 차원 축소(PCA), 정규화 회귀(Ridge/Lasso) 등이 있습니다.

## 3. 여러 분류 모델링 및 비교 ⚙️

4가지 기본 모델을 만들어 성능을 비교했다. 이번 문제에서는 **실제 예금 고객을 놓치지 않는 것**이 중요하므로 **재현율(Recall)**을 핵심 지표로 삼았다.

-   **Decision Tree (의사결정 나무)**
-   **Random Forest (랜덤 포레스트)**
-   **K-Nearest Neighbors (K-최근접 이웃)**
-   **Logistic Regression (로지스틱 회귀)**

```python
# 평가 지표를 한 번에 계산하는 함수 정의
def evaluate_model(model, x_test, y_test):
    from sklearn import metrics
    y_pred = model.predict(x_test)
    acc = metrics.accuracy_score(y_test, y_pred)
    prec = metrics.precision_score(y_test, y_pred)
    rec = metrics.recall_score(y_test, y_pred, average='weighted')
    f1 = metrics.f1_score(y_test, y_pred)
    # ... (AUC, Confusion Matrix 등)
    return {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, ...}
```

### 모델 비교 결과
-   전반적인 성능(정확도, AUC)은 **랜덤 포레스트**가 가장 우수했다.
-   하지만 재현율(Recall) 측면에서는 다른 모델들과 큰 차이가 없거나 오히려 낮을 때도 있었다.
-   시각화 차트를 통해 각 모델의 장단점을 한눈에 파악할 수 있었다.

## 4. 하이퍼파라미터 튜닝으로 모델 최적화 🛠️

가장 성능이 좋았던 랜덤 포레스트 모델을 `RandomizedSearchCV`를 사용해 최적화했다. 모든 파라미터 조합을 다 해보는 `GridSearchCV`보다 훨씬 효율적이었다.

```python
from sklearn.model_selection import RandomizedSearchCV

param_grid = {
    'max_depth': [50, 80, 100],
    'max_features': [2, 3, 4],
    'min_samples_leaf': [3, 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [100, 300, 500]
}

rfc = ensemble.RandomForestClassifier(random_state=42)
rm_model = RandomizedSearchCV(rfc, param_distributions=param_grid, cv=5, scoring='recall', n_iter=5)
rm_model.fit(X_train, y_train)

print(f"최적 파라미터: {rm_model.best_params_}")
```

-   **결과**: 아쉽게도 튜닝 후 재현율이 오히려 감소했다. 이는 기본 모델이 이미 꽤 괜찮았거나, 탐색한 파라미터 공간이 최적이 아니었을 수 있다는 의미다. 무조건 **튜닝이 능사는 아니다**라는 교훈을 얻었다.

## 5. AutoML 도구(PyCaret) 활용기 🤖

몇 줄의 코드로 전체 머신러닝 파이프라인을 자동화하는 PyCaret을 사용해봤다. 정말 신세계였다!

```python
from pycaret.classification import *

# 데이터와 타겟만 설정해주면 끝!
s = setup(df_bank_ready2, target = 'y', session_id = 123)

# 모든 모델을 비교하고 가장 좋은 모델을 알려준다.
best = compare_models()

# 베스트 모델을 자동으로 튜닝까지!
tuned_best_model = tune_model(best)
```

-   **경험**: 데이터 전처리부터 모델 비교, 튜닝까지 모든 과정을 자동화해주어 생산성이 엄청나게 향상됐다. 복잡한 프로젝트 초기에 빠르게 베이스라인 모델을 만들 때 정말 유용할 것 같다.

## 6. 최종 정리 및 회고 ✍️

- **데이터 불균형** 문제의 중요성을 체감했고, 상황에 맞는 **전처리**와 **평가 지표(재현율!)** 선택이 얼마나 중요한지 깨달았다. 

- 여러 모델을 직접 만들고 비교하며 각 알고리즘의 장단점을 파악할 수 있었고, `RandomizedSearchCV`를 통한 **하이퍼파라미터 튜닝**이 항상 성능 향상을 보장하는 것은 아니라는 현실적인 교훈을 얻었다.

- 마지막으로 **PyCaret** 같은 AutoML 도구의 강력함을 맛보며, 앞으로는 더 빠르고 효율적으로 모델링을 시작할 수 있겠다는 자신감이 생겼다. :muscle:
