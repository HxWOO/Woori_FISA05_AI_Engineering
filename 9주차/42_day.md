# ğŸ«‚ K-í‰ê· (K-Means) êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜

## ëª©ì°¨
1.  [K-í‰ê· (K-Means) ì•Œê³ ë¦¬ì¦˜ ê°œìš”](#1-k-í‰ê· k-means-ì•Œê³ ë¦¬ì¦˜-ê°œìš”)
2.  [K-í‰ê·  vs. K-NN](#2-k-í‰ê· -vs-k-nn)
3.  [K-í‰ê·  ì•Œê³ ë¦¬ì¦˜ ë™ì‘ ë°©ì‹](#3-k-í‰ê· -ì•Œê³ ë¦¬ì¦˜-ë™ì‘-ë°©ì‹)
4.  [Scikit-learnì„ ì´ìš©í•œ K-í‰ê·  êµ¬í˜„](#4-scikit-learnì„-ì´ìš©í•œ-k-í‰ê· -êµ¬í˜„)
5.  [ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜(K) ì°¾ê¸°: ì—˜ë³´ìš° ê¸°ë²•](#5-ìµœì ì˜-í´ëŸ¬ìŠ¤í„°-ê°œìˆ˜k-ì°¾ê¸°-ì—˜ë³´ìš°-ê¸°ë²•)
6.  [K-í‰ê·  ì•Œê³ ë¦¬ì¦˜ì˜ ì¥ë‹¨ì ](#6-k-í‰ê· -ì•Œê³ ë¦¬ì¦˜ì˜-ì¥ë‹¨ì )
7.  [ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê¸°ë²•](#7-ì„±ëŠ¥-í–¥ìƒì„-ìœ„í•œ-ê¸°ë²•)
8.  [êµ°ì§‘í™” ì„±ëŠ¥ í‰ê°€](#8-êµ°ì§‘í™”-ì„±ëŠ¥-í‰ê°€)
9.  [ë°€ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§: DBSCAN](#9-ë°€ë„-ê¸°ë°˜-í´ëŸ¬ìŠ¤í„°ë§-dbscan)

---

### 1. K-í‰ê· (K-Means) ì•Œê³ ë¦¬ì¦˜ ê°œìš”

-   **ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)**: ì •ë‹µ(ë ˆì´ë¸”)ì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ëŠ” **êµ°ì§‘í™”(Clustering)** ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
-   **ëª©í‘œ**: ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ **Kê°œì˜ êµ°ì§‘(Cluster)**ìœ¼ë¡œ ë¬¶ì–´, êµ°ì§‘ ë‚´ ë°ì´í„°ë“¤ì˜ ìœ ì‚¬ì„±ì€ ìµœëŒ€í™”í•˜ê³  êµ°ì§‘ ê°„ì˜ ìœ ì‚¬ì„±ì€ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤. âœ¨

    ![](https://stanford.edu/~cpiech/cs221/img/kmeansViz.png)

### 2. K-í‰ê·  vs. K-NN

| êµ¬ë¶„ | K-í‰ê·  (K-Means) | K-ìµœê·¼ì ‘ ì´ì›ƒ (K-NN) |
| :--- | :--- | :--- |
| **í•™ìŠµ ë°©ì‹** | ë¹„ì§€ë„í•™ìŠµ (Clustering) | ì§€ë„í•™ìŠµ (Classification) |
| **ëª©í‘œ** | ë ˆì´ë¸” ì—†ëŠ” ë°ì´í„°ë¥¼ Kê°œì˜ êµ°ì§‘ìœ¼ë¡œ ë‚˜ëˆ” | ìƒˆ ë°ì´í„°ì˜ í´ë˜ìŠ¤ë¥¼ Kê°œì˜ ì´ì›ƒì„ í†µí•´ ê²°ì • |
| **ê³µí†µì ** | Kê°œì˜ ì ì„ ì§€ì •í•˜ê³ , ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ |

### 3. K-í‰ê·  ì•Œê³ ë¦¬ì¦˜ ë™ì‘ ë°©ì‹

K-í‰ê· ì€ ì¤‘ì‹¬ì (Centroid)ì„ ì´ë™ì‹œì¼œê°€ë©° ìµœì ì˜ êµ°ì§‘ì„ í˜•ì„±í•œë‹¤.

1.  **ì´ˆê¸°í™”**: Kê°œì˜ ì¤‘ì‹¬ì (Centroid)ì„ ì„ì˜ì˜ ìœ„ì¹˜ì— ë°°ì¹˜í•œë‹¤.
2.  **êµ°ì§‘ í• ë‹¹**: ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ì— í• ë‹¹í•œë‹¤.
3.  **ì¤‘ì‹¬ì  ì—…ë°ì´íŠ¸**: ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ìœ¼ë¡œ ì¤‘ì‹¬ì ì„ ì´ë™ì‹œí‚¨ë‹¤.
4.  **ë°˜ë³µ**: ì¤‘ì‹¬ì ì´ ë” ì´ìƒ ì´ë™í•˜ì§€ ì•Šì„ ë•Œ(ìˆ˜ë ´)ê¹Œì§€ 2, 3ë²ˆ ê³¼ì •ì„ ë°˜ë³µí•œë‹¤. ì´ ê³¼ì •ì´ ëë‚˜ë©´ ìµœì ì˜ êµ°ì§‘ì´ ë§Œë“¤ì–´ì§„ë‹¤! ğŸ‰

### 4. Scikit-learnì„ ì´ìš©í•œ K-í‰ê·  êµ¬í˜„

ë¶“ê½ƒ(Iris) ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ K-í‰ê·  êµ°ì§‘í™”ë¥¼ ì‹¤ìŠµí–ˆë‹¤.

#### 4.1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ì¤€ë¹„

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans

# ë°ì´í„° ë¡œë“œ
iris = load_iris()
irisDF = pd.DataFrame(iris.data, columns=iris.feature_names)
```

#### 4.2. K-í‰ê·  ëª¨ë¸ í•™ìŠµ

`n_clusters` íŒŒë¼ë¯¸í„°ë¡œ êµ°ì§‘ì˜ ê°œìˆ˜(K)ë¥¼ ì§€ì •í–ˆë‹¤.

```python
# K=3ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ KMeans ê°ì²´ ìƒì„±
kmeans = KMeans(n_clusters=3, random_state=121)

# ëª¨ë¸ í•™ìŠµ
kmeans.fit(irisDF)

# ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ì†í•œ êµ°ì§‘ ë ˆì´ë¸” í™•ì¸
print(kmeans.labels_)
```

#### 4.3. ì£¼ìš” ì†ì„±

-   `cluster_centers_`: ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ì  ì¢Œí‘œ
-   `inertia_`: ê´€ì„±. í´ëŸ¬ìŠ¤í„° ë‚´ ë°ì´í„°ë“¤ì´ ì–¼ë§ˆë‚˜ ì˜ ë­‰ì³ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ (ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
-   `labels_`: ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ì†í•œ êµ°ì§‘ ë ˆì´ë¸”

```python
# ì¤‘ì‹¬ì  ì¢Œí‘œ ì¶œë ¥
print("ì¤‘ì‹¬ì  ì¢Œí‘œ:
", kmeans.cluster_centers_)

# ê´€ì„± ê°’ ì¶œë ¥
print("ê´€ì„±(Inertia):", kmeans.inertia_)
```

> **`inertia_`** ëŠ” í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ë¬´ì¡°ê±´ ê°ì†Œí•´ì„œ, ì´ ê°’ë§Œìœ¼ë¡œ ì¢‹ì€ êµ°ì§‘í™”ë¥¼ íŒë‹¨í•˜ê¸°ëŠ” ì–´ë µë‹¤. ğŸ¤”

### 5. ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜(K) ì°¾ê¸°: ì—˜ë³´ìš° ê¸°ë²•

**ì—˜ë³´ìš°(Elbow) ê¸°ë²•**ì€ Kê°’ì„ ëŠ˜ë ¤ê°€ë©´ì„œ `inertia_` ê°’ì˜ ë³€í™”ë¥¼ ê´€ì°°í•˜ì—¬ ìµœì ì˜ Kë¥¼ ì°¾ëŠ” ë°©ë²•ì´ë‹¤. ê·¸ë˜í”„ì—ì„œ ê¸°ìš¸ê¸°ê°€ ê¸‰ê²©íˆ ì™„ë§Œí•´ì§€ëŠ” ì§€ì (Elbow)ì„ ìµœì ì˜ Kë¡œ íŒë‹¨í–ˆë‹¤.

```python
inertias = []
K_range = range(1, 12)

for k in K_range:
    km = KMeans(n_clusters=k, random_state=121)
    km.fit(iris.data)
    inertias.append(km.inertia_)

# ê·¸ë˜í”„ë¡œ ì‹œê°í™”
plt.plot(K_range, inertias, '-o')
plt.xlabel('Number of clusters, K')
plt.ylabel('Inertia')
plt.xticks(K_range)
plt.title('Elbow Method for Optimal K')
plt.show()
```

### 6. K-í‰ê·  ì•Œê³ ë¦¬ì¦˜ì˜ ì¥ë‹¨ì 

| ì¥ì  | ë‹¨ì  |
| :--- | :--- |
| ì´í•´ì™€ êµ¬í˜„ì´ ì‰½ê³  ì§ê´€ì  | **Kê°’ì„ ì§ì ‘ ì„¤ì •**í•´ì•¼ í•¨ |
| ìˆ˜ë ´ì„±ì´ ë³´ì¥ë¨ | **ê±°ë¦¬ ê¸°ë°˜**ì´ë¼ ì°¨ì›ì´ ë§ì•„ì§€ë©´ ë³µì¡ë„ ì¦ê°€ |
| ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì ìš© ê°€ëŠ¥ | **ì´ìƒì¹˜(Outlier)ì™€ ìŠ¤ì¼€ì¼**ì— ë¯¼ê°í•¨ |
| - | ì´ˆê¸° ì¤‘ì‹¬ì  ìœ„ì¹˜ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ |

### 7. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê¸°ë²•

-   **PCA (ì°¨ì› ì¶•ì†Œ)**: ê±°ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì˜ ê³„ì‚° ë³µì¡ë„ë¥¼ ì¤„ì—¬ì£¼ì—ˆë‹¤.
-   **ìŠ¤ì¼€ì¼ë§ (Scaling)**: `StandardScaler` ë“±ì„ ì‚¬ìš©í•˜ì—¬ í”¼ì²˜ì˜ ìŠ¤ì¼€ì¼ì„ ë§ì¶°ì£¼ë‹ˆ ì´ìƒì¹˜ì— ëŒ€í•œ ë¯¼ê°ë„ë¥¼ ì¤„ì¼ ìˆ˜ ìˆì—ˆë‹¤. ğŸ‘

```python
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_scaled = scaler.fit_transform(iris.data)

# PCAë¡œ ì°¨ì› ì¶•ì†Œ
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# K-Means í•™ìŠµ
kmeans_pca = KMeans(n_clusters=3, random_state=121)
kmeans_pca.fit(X_pca)
```

### 8. êµ°ì§‘í™” ì„±ëŠ¥ í‰ê°€

#### 8.1. ì‹¤ë£¨ì—£ ê³„ìˆ˜ (Silhouette Coefficient)

-   **ì •ë‹µ ë ˆì´ë¸”ì´ ì—†ëŠ” ê²½ìš°** ì‚¬ìš©í–ˆë‹¤.
-   êµ°ì§‘ ë‚´ ë°ì´í„°ëŠ” ì–¼ë§ˆë‚˜ ê°€ê¹ê³ , ë‹¤ë¥¸ êµ°ì§‘ê³¼ëŠ” ì–¼ë§ˆë‚˜ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œë‹¤.
-   ê°’ì˜ ë²”ìœ„ëŠ” **-1ì—ì„œ 1 ì‚¬ì´**ì´ë©°, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ êµ°ì§‘í™”ë¡œ íŒë‹¨í–ˆë‹¤.

```python
from sklearn.metrics import silhouette_score, silhouette_samples

# ì‹¤ë£¨ì—£ ê³„ìˆ˜ ê³„ì‚° (ì „ì²´ í‰ê· )
score = silhouette_score(iris.data, kmeans.labels_)
print('ì‹¤ë£¨ì—£ ì ìˆ˜: {0:.3f}'.format(score))
```

#### 8.2. Homogeneity, Completeness, V-measure

-   **ì •ë‹µ ë ˆì´ë¸”ì´ ìˆëŠ” ê²½ìš°** ì‚¬ìš©í–ˆë‹¤.
-   **Homogeneity (ê· ì§ˆì„±)**: ê° êµ°ì§‘ì´ ë™ì¼í•œ ì‹¤ì œ í´ë˜ìŠ¤ë¡œ êµ¬ì„±ëœ ì •ë„ (ì •ë°€ë„ì™€ ìœ ì‚¬).
-   **Completeness (ì™„ì „ì„±)**: ê° ì‹¤ì œ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë“¤ì´ ë™ì¼í•œ êµ°ì§‘ìœ¼ë¡œ êµ¬ì„±ëœ ì •ë„ (ì¬í˜„ìœ¨ê³¼ ìœ ì‚¬).
-   **V-measure**: ê· ì§ˆì„±ê³¼ ì™„ì „ì„±ì˜ ì¡°í™” í‰ê· ì´ë‹¤.

```python
from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score

# ì‹¤ì œê°’(iris.target)ê³¼ ì˜ˆì¸¡ê°’(kmeans.labels_) ë¹„êµ
print("ê· ì§ˆì„±:", homogeneity_score(iris.target, kmeans.labels_))
print("ì™„ì „ì„±:", completeness_score(iris.target, kmeans.labels_))
print("V-measure:", v_measure_score(iris.target, kmeans.labels_))
```

### 9. ë°€ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§: DBSCAN

-   **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** ì€ ë°ì´í„°ê°€ ë°€ì§‘ëœ ì§€ì—­ì„ ì°¾ì•„ êµ°ì§‘í™”í•˜ëŠ” ë°©ì‹ì´ë‹¤.
-   K-í‰ê· ê³¼ ë‹¬ë¦¬ **í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ ì •í•  í•„ìš”ê°€ ì—†ê³ **, ë…¸ì´ì¦ˆ(ì´ìƒì¹˜)ë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•´ì¤˜ì„œ í¸ë¦¬í–ˆë‹¤.
-   ì£¼ìš” íŒŒë¼ë¯¸í„°ëŠ” `eps` (ì´ì›ƒìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ìµœëŒ€ ê±°ë¦¬)ì™€ `min_samples` (êµ°ì§‘ì„ ì´ë£¨ëŠ” ìµœì†Œ ìƒ˜í”Œ ìˆ˜)ì´ë‹¤.

```python
from sklearn.cluster import DBSCAN

# DBSCAN ê°ì²´ ìƒì„± ë° í•™ìŠµ
dbscan = DBSCAN(eps=0.6, min_samples=8)
dbscan_labels = dbscan.fit_predict(iris.data)

# -1ì€ ë…¸ì´ì¦ˆ(ì´ìƒì¹˜)ë¡œ ë¶„ë¥˜ëœ ë°ì´í„°
print(np.unique(dbscan_labels, return_counts=True))
```